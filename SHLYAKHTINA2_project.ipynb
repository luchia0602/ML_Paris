{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6925307a",
   "metadata": {},
   "source": [
    "Python Data Analysis project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4db100",
   "metadata": {},
   "source": [
    "Shlyakhtina Liudmila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1bd386ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8052fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  1 4826k    1 92990    0     0  73858      0  0:01:06  0:00:01  0:01:05 74154\n",
      " 39 4826k   39 1914k    0     0   851k      0  0:00:05  0:00:02  0:00:03  853k\n",
      "100 4826k  100 4826k    0     0  1497k      0  0:00:03  0:00:03 --:--:-- 1500k\n"
     ]
    }
   ],
   "source": [
    "# Download UD dataset.\n",
    "!curl -O https://pages.llf-paris.fr/~gwisniewski/assets/2025/transfer_scores.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2a5991",
   "metadata": {},
   "source": [
    "1.  Briefly describe the task of PoS tagging. Why is the ability to predict PoS tags  still useful in the era of ChatGPT-like models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c453c96",
   "metadata": {},
   "source": [
    "==>  PoS tagging is the task of assigning a word its part of speech, morphosyntactic category (such as noun, adverb, verb etc.) It is still useful in tasks such as dependency parsing, named entity recognition and information extraction. For example, PoS tagging is used in TTS since it helps with natural intonation by ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99f2d67",
   "metadata": {},
   "source": [
    " 2. Why should training and test corpora be kept separate? Is the use of predefined train–test splits, as in the UD project, a good idea or not? Motivate your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfd214a",
   "metadata": {},
   "source": [
    "==> If test corpora is a part of the training one, the model might overfit: it would see the correct predictions during the training state and will perform perfectly in the evaluation stage. That does not mean the model actually learned something: it just learned to predict the correct answers. That is why data is usually split into train and test sets (sometimes val for adjusting hyperparameters) so the model's performance can be judged fairly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076c8936",
   "metadata": {},
   "source": [
    " 3. Why are the data stored in a TSV rather than a CSV format? How can they be  loaded into a dataframe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc842b6d",
   "metadata": {},
   "source": [
    "==> Because columns are separated not by commas (as in CSV format) but by tabs. In order to load it, one should just add that separator is tab as done below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bafa8fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43490 entries, 0 to 43489\n",
      "Data columns (total 19 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   target_lang  43490 non-null  object \n",
      " 1   model_lang   43490 non-null  object \n",
      " 2   target_ud    43490 non-null  object \n",
      " 3   model_ud     43490 non-null  object \n",
      " 4   Tokens       43490 non-null  float64\n",
      " 5   Sentences    43490 non-null  float64\n",
      " 6   Words        43490 non-null  float64\n",
      " 7   UPOS         43490 non-null  float64\n",
      " 8   XPOS         43490 non-null  float64\n",
      " 9   UFeats       43490 non-null  float64\n",
      " 10  AllTags      43490 non-null  float64\n",
      " 11  Lemmas       43490 non-null  float64\n",
      " 12  UAS          43490 non-null  float64\n",
      " 13  LAS          43490 non-null  float64\n",
      " 14  CLAS         43490 non-null  float64\n",
      " 15  MLAS         43490 non-null  float64\n",
      " 16  BLEX         43490 non-null  float64\n",
      " 17  target_iso3  43343 non-null  object \n",
      " 18  model_iso3   43490 non-null  object \n",
      "dtypes: float64(13), object(6)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('transfer_scores.tsv',sep='\\t') \n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e1694e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_lang</th>\n",
       "      <th>model_lang</th>\n",
       "      <th>target_ud</th>\n",
       "      <th>model_ud</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Words</th>\n",
       "      <th>UPOS</th>\n",
       "      <th>XPOS</th>\n",
       "      <th>UFeats</th>\n",
       "      <th>AllTags</th>\n",
       "      <th>Lemmas</th>\n",
       "      <th>UAS</th>\n",
       "      <th>LAS</th>\n",
       "      <th>CLAS</th>\n",
       "      <th>MLAS</th>\n",
       "      <th>BLEX</th>\n",
       "      <th>target_iso3</th>\n",
       "      <th>model_iso3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abkhaz</td>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>ab_abnc</td>\n",
       "      <td>af_afribooms</td>\n",
       "      <td>99.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.95</td>\n",
       "      <td>28.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32.32</td>\n",
       "      <td>9.21</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>abk</td>\n",
       "      <td>afr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abkhaz</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>ab_abnc</td>\n",
       "      <td>ar_padt</td>\n",
       "      <td>98.69</td>\n",
       "      <td>6.38</td>\n",
       "      <td>98.69</td>\n",
       "      <td>27.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.32</td>\n",
       "      <td>9.68</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abk</td>\n",
       "      <td>arb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abkhaz</td>\n",
       "      <td>Belarusian</td>\n",
       "      <td>ab_abnc</td>\n",
       "      <td>be_hse</td>\n",
       "      <td>99.51</td>\n",
       "      <td>78.49</td>\n",
       "      <td>99.51</td>\n",
       "      <td>43.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32.10</td>\n",
       "      <td>20.10</td>\n",
       "      <td>10.62</td>\n",
       "      <td>4.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>abk</td>\n",
       "      <td>bel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abkhaz</td>\n",
       "      <td>Bulgarian</td>\n",
       "      <td>ab_abnc</td>\n",
       "      <td>bg_btb</td>\n",
       "      <td>99.95</td>\n",
       "      <td>31.17</td>\n",
       "      <td>99.95</td>\n",
       "      <td>36.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.21</td>\n",
       "      <td>18.90</td>\n",
       "      <td>6.99</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abk</td>\n",
       "      <td>bul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abkhaz</td>\n",
       "      <td>Catalan</td>\n",
       "      <td>ab_abnc</td>\n",
       "      <td>ca_ancora</td>\n",
       "      <td>99.88</td>\n",
       "      <td>50.22</td>\n",
       "      <td>99.88</td>\n",
       "      <td>33.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.59</td>\n",
       "      <td>8.89</td>\n",
       "      <td>4.63</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abk</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43485</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>zh_pud</td>\n",
       "      <td>vi_vtb</td>\n",
       "      <td>21.49</td>\n",
       "      <td>96.20</td>\n",
       "      <td>21.49</td>\n",
       "      <td>19.60</td>\n",
       "      <td>16.77</td>\n",
       "      <td>21.19</td>\n",
       "      <td>16.68</td>\n",
       "      <td>21.20</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.23</td>\n",
       "      <td>cmn</td>\n",
       "      <td>vie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43486</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Wolof</td>\n",
       "      <td>zh_pud</td>\n",
       "      <td>wo_wtb</td>\n",
       "      <td>12.02</td>\n",
       "      <td>98.80</td>\n",
       "      <td>12.02</td>\n",
       "      <td>10.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>cmn</td>\n",
       "      <td>wol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43487</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Classical Armenian</td>\n",
       "      <td>zh_pud</td>\n",
       "      <td>xcl_caval</td>\n",
       "      <td>15.61</td>\n",
       "      <td>96.88</td>\n",
       "      <td>15.61</td>\n",
       "      <td>14.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>cmn</td>\n",
       "      <td>xcl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43488</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>zh_pud</td>\n",
       "      <td>zh_gsd</td>\n",
       "      <td>88.01</td>\n",
       "      <td>97.47</td>\n",
       "      <td>88.01</td>\n",
       "      <td>78.89</td>\n",
       "      <td>84.61</td>\n",
       "      <td>86.67</td>\n",
       "      <td>77.60</td>\n",
       "      <td>87.95</td>\n",
       "      <td>60.73</td>\n",
       "      <td>49.41</td>\n",
       "      <td>43.02</td>\n",
       "      <td>34.71</td>\n",
       "      <td>42.99</td>\n",
       "      <td>cmn</td>\n",
       "      <td>cmn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43489</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>zh_pud</td>\n",
       "      <td>zh_gsdsimp</td>\n",
       "      <td>57.82</td>\n",
       "      <td>99.55</td>\n",
       "      <td>57.82</td>\n",
       "      <td>50.53</td>\n",
       "      <td>55.38</td>\n",
       "      <td>56.41</td>\n",
       "      <td>49.33</td>\n",
       "      <td>57.74</td>\n",
       "      <td>23.72</td>\n",
       "      <td>20.50</td>\n",
       "      <td>14.33</td>\n",
       "      <td>11.50</td>\n",
       "      <td>14.31</td>\n",
       "      <td>cmn</td>\n",
       "      <td>cmn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43490 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target_lang          model_lang target_ud      model_ud  Tokens  \\\n",
       "0          Abkhaz           Afrikaans   ab_abnc  af_afribooms   99.95   \n",
       "1          Abkhaz              Arabic   ab_abnc       ar_padt   98.69   \n",
       "2          Abkhaz          Belarusian   ab_abnc        be_hse   99.51   \n",
       "3          Abkhaz           Bulgarian   ab_abnc        bg_btb   99.95   \n",
       "4          Abkhaz             Catalan   ab_abnc     ca_ancora   99.88   \n",
       "...           ...                 ...       ...           ...     ...   \n",
       "43485     Chinese          Vietnamese    zh_pud        vi_vtb   21.49   \n",
       "43486     Chinese               Wolof    zh_pud        wo_wtb   12.02   \n",
       "43487     Chinese  Classical Armenian    zh_pud     xcl_caval   15.61   \n",
       "43488     Chinese             Chinese    zh_pud        zh_gsd   88.01   \n",
       "43489     Chinese             Chinese    zh_pud    zh_gsdsimp   57.82   \n",
       "\n",
       "       Sentences  Words   UPOS   XPOS  UFeats  AllTags  Lemmas    UAS    LAS  \\\n",
       "0           0.00  99.95  28.32   0.00   37.12     0.00   32.32   9.21   3.94   \n",
       "1           6.38  98.69  27.87   0.00   41.87     0.00   31.32   9.68   3.01   \n",
       "2          78.49  99.51  43.37   0.00   35.47     0.00   32.10  20.10  10.62   \n",
       "3          31.17  99.95  36.96   0.00   33.60     0.00   31.21  18.90   6.99   \n",
       "4          50.22  99.88  33.26   0.00   44.30     0.00   31.59   8.89   4.63   \n",
       "...          ...    ...    ...    ...     ...      ...     ...    ...    ...   \n",
       "43485      96.20  21.49  19.60  16.77   21.19    16.68   21.20   1.39   1.28   \n",
       "43486      98.80  12.02  10.54   0.00   11.56     0.00   11.93   0.53   0.52   \n",
       "43487      96.88  15.61  14.16   0.00   14.83     0.00   15.14   0.19   0.15   \n",
       "43488      97.47  88.01  78.89  84.61   86.67    77.60   87.95  60.73  49.41   \n",
       "43489      99.55  57.82  50.53  55.38   56.41    49.33   57.74  23.72  20.50   \n",
       "\n",
       "        CLAS   MLAS   BLEX target_iso3 model_iso3  \n",
       "0       0.49   0.02   0.07         abk        afr  \n",
       "1       1.06   0.00   0.00         abk        arb  \n",
       "2       4.24   0.00   0.24         abk        bel  \n",
       "3       4.25   0.00   0.00         abk        bul  \n",
       "4       1.50   0.14   0.00         abk        cat  \n",
       "...      ...    ...    ...         ...        ...  \n",
       "43485   0.24   0.16   0.23         cmn        vie  \n",
       "43486   0.26   0.00   0.26         cmn        wol  \n",
       "43487   0.00   0.00   0.00         cmn        xcl  \n",
       "43488  43.02  34.71  42.99         cmn        cmn  \n",
       "43489  14.33  11.50  14.31         cmn        cmn  \n",
       "\n",
       "[43490 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb861a2",
   "metadata": {},
   "source": [
    " 4. How many different training corpora are available?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526beac",
   "metadata": {},
   "source": [
    "\"the language and UD corpus ID of the model (the corpus on which the model is\n",
    " trained) — columns model_lang and model_ud\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed3cf22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"model_ud\"].nunique() # Model_ud contains corpora for training according to the project description."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84997c76",
   "metadata": {},
   "source": [
    "5. How many different test corpora are available?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19c49a7",
   "metadata": {},
   "source": [
    "\"the language and UD corpus ID of the evaluation data — columns target_lang and target_ud\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd86acdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"target_ud\"].nunique() # As said in the description, a corpus can appear in target_ud even if it has no training data, therefore we take unique values in target_ud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cdeb0c",
   "metadata": {},
   "source": [
    "6. How many different languages are represented in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ea6672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(data[\"model_lang\"]).union(set(data[\"target_lang\"]))) \n",
    "# We count both train and test languages since some of the languages are test only. \n",
    "# Set and union are used to avoid dublicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f413a60a",
   "metadata": {},
   "source": [
    " 7. Plot the distribution of the number of corpora per language (x-axis : number of corpora; y-axis : number of languages with that number of corpora)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04b0492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='count'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = pd.Series(pd.concat([data.model_ud, data.target_ud]).str.split(\"_\").str[0]).value_counts().value_counts().sort_index()\n",
    "dist.plot(kind=\"bar\") # Here we take all corpora id by extracting language code before \"_\" (e.g. be_hse -> be), then count how many languages have that number of corpora and sort by number for the graph.\n",
    "# First value_counts: how many corpora per language, second value_counts: how many languages have that number of corpora."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2701b6fc",
   "metadata": {},
   "source": [
    " 8. How many languages have three training corpora?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38754704",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = data.groupby(\"model_lang\")[\"model_ud\"].nunique() \n",
    "len(counts[counts==3])\n",
    "# We group the data by model_lang, count how many distinct corpora each language has,\n",
    "# keep only languages that satisfy the condition 'count is exactly 3' and count how many such languages there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e19e5fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_lang\n",
       "Ancient Greek    3\n",
       "Hebrew           3\n",
       "Icelandic        3\n",
       "Korean           3\n",
       "Romanian         3\n",
       "Name: model_ud, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.groupby(\"model_lang\")[\"model_ud\"].nunique())[counts==3] # These are the languages with exactly 3 training corpora."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f20256",
   "metadata": {},
   "source": [
    " 9. Which language has the highest number of corpora?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60de89d",
   "metadata": {},
   "source": [
    "It was not quite clear for me which kind of corpora is needed so I did all the three cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54629eb4",
   "metadata": {},
   "source": [
    "9.1 Which language has the highest number of test corpora?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb6a542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"target_lang\")[\"target_ud\"].nunique().idxmax() # We count distinct evaluation corpora per language and get the highest with idxmax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2029678e",
   "metadata": {},
   "source": [
    "9.2 Which language has the highest number of training corpora?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ea87d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italian'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"model_lang\")[\"model_ud\"].nunique().idxmax() # Same code as above, just replace test variables with train variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f3f7b7",
   "metadata": {},
   "source": [
    "9.3 Which language has the highest number of combined corpora?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ce169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italian'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we just combine two lines from above and only apply idxmax in the end.\n",
    "(data.groupby(\"model_lang\")[\"model_ud\"].nunique().add(data.groupby(\"target_lang\")[\"target_ud\"].nunique())).idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fefed0",
   "metadata": {},
   "source": [
    "ANALYSIS OF SCORES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ced333",
   "metadata": {},
   "source": [
    " 10. Considering only the in-domain scores (same train and test corpus), compute the mean, median, minimum, and maximum scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58645be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean      95.176667\n",
       "median    96.910000\n",
       "min       73.380000\n",
       "max       99.730000\n",
       "Name: UPOS, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data[\"model_lang\"] == data[\"target_lang\"]) & (data[\"model_ud\"] == data[\"target_ud\"])][\"UPOS\"].agg(['mean', 'median', 'min', 'max'])\n",
    "# Filter rows where training corpus and test corpus are the same, extract UPOS values and compute the four main stats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5fc6c3",
   "metadata": {},
   "source": [
    "11. Answer the same questions while considering only the out-of-domain scores (train and test corpora differ, but the language is the same). Comment on your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9d6a583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean      85.024837\n",
       "median    91.030000\n",
       "min        0.170000\n",
       "max       98.860000\n",
       "Name: UPOS, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data[\"model_lang\"] == data[\"target_lang\"]) & (data[\"model_ud\"] != data[\"target_ud\"])][\"UPOS\"].agg(['mean', 'median', 'min', 'max'])\n",
    "# The code is similar to the one above, but the condition changed to 'same language, different corpora'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ec32cb",
   "metadata": {},
   "source": [
    "==> One could notice that in the latter case (different corpora) performance drops (by -10.15% for mean, -5.88% for median, -73.21% for min, -0.87% for max).\n",
    "However, it does not mean that in-domain scores are any better that the out-of-domain ones. This is exactly what we have talked about back in question 2: even though in-domains scores might be near perfect, they do not repressent the model's performace since test data had been leaked during training phase. The model learned to predict the data for evaluation while training and performs perfect on that exact data during evaluation, which is not suprising. Therefore, we cannot assess the real model's quality in this case since it alreaady saw the gold classes, correct UPOS labels here, during training phase.\n",
    "\n",
    "The second case, on the other hand, is much more informative. It actually judges the models' performance since the golden rule 'do not mix training and test sets' was not broken. Out of all the models presented in this dataset, the mean of predicting tags correctly is 85% while median is 91%. Even though the numbers themselves look promising, it would be useful to have some kind of baseline to compare UD's performance but there is none given in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b391091",
   "metadata": {},
   "source": [
    "12. Repeat the same questions for the cross-lingual transfer scores (train and test languages differ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764c8d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean     NaN\n",
       "median   NaN\n",
       "min      NaN\n",
       "max      NaN\n",
       "Name: UPOS, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data[\"model_lang\"] != data[\"target_lang\"]) & (data[\"model_ud\"] == data[\"target_ud\"])][\"UPOS\"].agg(['mean', 'median', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab7208e",
   "metadata": {},
   "source": [
    "==> As the table above shows, there is no data found where languages are different but corpora is the same. It is not surprising, though, since there are no corpora for two different languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25bdaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean      35.024062\n",
       "median    34.030000\n",
       "min        0.000000\n",
       "max       98.520000\n",
       "Name: UPOS, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data[\"model_lang\"] != data[\"target_lang\"]) & (data[\"model_ud\"] != data[\"target_ud\"])][\"UPOS\"].agg(['mean', 'median', 'min', 'max'])\n",
    "# One could remove the second condition here since there are no corpora with different languages and run this instead:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182bfcb3",
   "metadata": {},
   "source": [
    "==> This result is the most important for this project, showing exactly the performance of cross-lingual model transfer: without breaking the golden rule of not mixing train and test sets together, how well can a model trained on train data from language A perform on test data from language B? As it turns out, not that well: only 35% of the UPoS tags were correctly predicted. In some extreme case none of the tags were predicted correctly; however, for some case a fantastic percentage of 98.52% correctly predicted tags was reached."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61910d3b",
   "metadata": {},
   "source": [
    "13. Construct a dataframe that, for each French test corpus, contains the following information :\n",
    " \n",
    " — the in-domain performance (if available, otherwise NaN),\n",
    " \n",
    " — the best out-of-domain performance,\n",
    " \n",
    " — the best cross-lingual transfer performance,\n",
    " \n",
    " — the language achieving this best transfer score.\n",
    " \n",
    " Provide a short commentary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8f65288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\localuser\\AppData\\Local\\Temp\\ipykernel_28956\\66162783.py:1: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  fr_data = data.query(\"target_lang == 'French'\").groupby(\"target_ud\").apply(lambda g: pd.Series({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_ud</th>\n",
       "      <th>in_domain</th>\n",
       "      <th>best_out_domain</th>\n",
       "      <th>best_cross_lingual</th>\n",
       "      <th>best_transfer_lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fr_fqb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.17</td>\n",
       "      <td>80.49</td>\n",
       "      <td>Catalan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fr_gsd</td>\n",
       "      <td>97.47</td>\n",
       "      <td>96.72</td>\n",
       "      <td>84.12</td>\n",
       "      <td>Catalan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fr_parisstories</td>\n",
       "      <td>97.45</td>\n",
       "      <td>96.98</td>\n",
       "      <td>80.06</td>\n",
       "      <td>Old French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fr_partut</td>\n",
       "      <td>97.78</td>\n",
       "      <td>96.00</td>\n",
       "      <td>85.89</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fr_pud</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.21</td>\n",
       "      <td>85.20</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fr_rhapsodie</td>\n",
       "      <td>97.45</td>\n",
       "      <td>97.03</td>\n",
       "      <td>84.28</td>\n",
       "      <td>Old French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fr_sequoia</td>\n",
       "      <td>98.38</td>\n",
       "      <td>96.96</td>\n",
       "      <td>83.35</td>\n",
       "      <td>Catalan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target_ud  in_domain  best_out_domain  best_cross_lingual  \\\n",
       "0           fr_fqb        NaN            96.17               80.49   \n",
       "1           fr_gsd      97.47            96.72               84.12   \n",
       "2  fr_parisstories      97.45            96.98               80.06   \n",
       "3        fr_partut      97.78            96.00               85.89   \n",
       "4           fr_pud        NaN            96.21               85.20   \n",
       "5     fr_rhapsodie      97.45            97.03               84.28   \n",
       "6       fr_sequoia      98.38            96.96               83.35   \n",
       "\n",
       "  best_transfer_lang  \n",
       "0            Catalan  \n",
       "1            Catalan  \n",
       "2         Old French  \n",
       "3            Italian  \n",
       "4            Italian  \n",
       "5         Old French  \n",
       "6            Catalan  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_data = data.query(\"target_lang == 'French'\").groupby(\"target_ud\").apply(lambda g: pd.Series({\n",
    "    \"in_domain\": g.query(\"model_lang == 'French' and model_ud == target_ud\").UPOS.max(), # This is just copied from above.\n",
    "    \"best_out_domain\": g.query(\"model_lang == 'French' and model_ud != target_ud\").UPOS.max(),\n",
    "    \"best_cross_lingual\": g.query(\"model_lang != 'French'\").UPOS.max(), # We do not need to specify that corpora is not same due to explanations above.\n",
    "    \"best_transfer_lang\": g.query(\"model_lang != 'French'\").loc[lambda x: x.UPOS.idxmax(), \"model_lang\"] \n",
    "})).reset_index()\n",
    "fr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996c399e",
   "metadata": {},
   "source": [
    "==> There are six distinct French corpora found. Two of them have no data on in-domain performace; others scored no less than 97.45% labels correctly predicted on themselves.\n",
    "\n",
    "Models trained on French and tested on other French corpora also perform well, 96.00% being the worst score.\n",
    "\n",
    "Performance drops on cross-lingual transfer cases. It is still considerably good since all the scores are in range 80.06, 85.89.\n",
    "\n",
    "Finally, it is most interesting to look at the languages that performed the best in cross-lingual transfer situations. And it is not surprising that those languages are relatives of French, namely Italian, Old French and Catalan, all coming from Romance languages group. \n",
    "\n",
    "Conclusion: UPoS-predictors performed best on related languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de309322",
   "metadata": {},
   "source": [
    " 14. How many different languages achieve the best transfer score (considering all French test corpora)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b93d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_data['best_transfer_lang'].nunique() # Just take the column from new DataFrame above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17495b9b",
   "metadata": {},
   "source": [
    " 15. Plot the distribution of in-domain, out-of-domain, and cross-lingual transfer scores across all test corpora using a violin plot. Interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d47b07bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `UPOS` for `y`. An entry with this name does not appear in `data`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m fr_data_m = fr_data.melt(\n\u001b[32m      2\u001b[39m     id_vars=[\u001b[33m'\u001b[39m\u001b[33mtarget_ud\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      3\u001b[39m     value_vars=[\u001b[33m'\u001b[39m\u001b[33min_domain\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbest_out_domain\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbest_transfer_lang\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      4\u001b[39m     var_name=\u001b[33m'\u001b[39m\u001b[33mscore_type\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      5\u001b[39m     value_name=\u001b[33m'\u001b[39m\u001b[33mUPOs\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      6\u001b[39m )\n\u001b[32m      8\u001b[39m pyplot.figure(figsize=(\u001b[32m10\u001b[39m,\u001b[32m6\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43msns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mviolinplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mscore_type\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mUPOS\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfr_data_m\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mquartile\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSet2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m pyplot.ylabel(\u001b[33m'\u001b[39m\u001b[33mUPOS score\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     11\u001b[39m pyplot.xlabel(\u001b[33m'\u001b[39m\u001b[33mEvaluation Type\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\localuser\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\seaborn\\categorical.py:1725\u001b[39m, in \u001b[36mviolinplot\u001b[39m\u001b[34m(data, x, y, hue, order, hue_order, orient, color, palette, saturation, fill, inner, split, width, dodge, gap, linewidth, linecolor, cut, gridsize, bw_method, bw_adjust, density_norm, common_norm, hue_norm, formatter, log_scale, native_scale, legend, scale, scale_hue, bw, inner_kws, ax, **kwargs)\u001b[39m\n\u001b[32m   1714\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mviolinplot\u001b[39m(\n\u001b[32m   1715\u001b[39m     data=\u001b[38;5;28;01mNone\u001b[39;00m, *, x=\u001b[38;5;28;01mNone\u001b[39;00m, y=\u001b[38;5;28;01mNone\u001b[39;00m, hue=\u001b[38;5;28;01mNone\u001b[39;00m, order=\u001b[38;5;28;01mNone\u001b[39;00m, hue_order=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1716\u001b[39m     orient=\u001b[38;5;28;01mNone\u001b[39;00m, color=\u001b[38;5;28;01mNone\u001b[39;00m, palette=\u001b[38;5;28;01mNone\u001b[39;00m, saturation=\u001b[32m.75\u001b[39m, fill=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1722\u001b[39m     inner_kws=\u001b[38;5;28;01mNone\u001b[39;00m, ax=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs,\n\u001b[32m   1723\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1725\u001b[39m     p = \u001b[43m_CategoricalPlotter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1726\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1727\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1728\u001b[39m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1729\u001b[39m \u001b[43m        \u001b[49m\u001b[43morient\u001b[49m\u001b[43m=\u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1730\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1731\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlegend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlegend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1732\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1735\u001b[39m         ax = plt.gca()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\localuser\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\seaborn\\categorical.py:67\u001b[39m, in \u001b[36m_CategoricalPlotter.__init__\u001b[39m\u001b[34m(self, data, variables, order, orient, require_numeric, color, legend)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     58\u001b[39m     data=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     legend=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     65\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# This method takes care of some bookkeeping that is necessary because the\u001b[39;00m\n\u001b[32m     70\u001b[39m     \u001b[38;5;66;03m# original categorical plots (prior to the 2021 refactor) had some rules that\u001b[39;00m\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# don't fit exactly into VectorPlotter logic. It may be wise to have a second\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m     \u001b[38;5;66;03m# default VectorPlotter rules. If we do decide to make orient part of the\u001b[39;00m\n\u001b[32m     77\u001b[39m     \u001b[38;5;66;03m# _base variable assignment, we'll want to figure out how to express that.\u001b[39;00m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.input_format == \u001b[33m\"\u001b[39m\u001b[33mwide\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mh\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\localuser\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\seaborn\\_base.py:634\u001b[39m, in \u001b[36mVectorPlotter.__init__\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m    629\u001b[39m \u001b[38;5;66;03m# var_ordered is relevant only for categorical axis variables, and may\u001b[39;00m\n\u001b[32m    630\u001b[39m \u001b[38;5;66;03m# be better handled by an internal axis information object that tracks\u001b[39;00m\n\u001b[32m    631\u001b[39m \u001b[38;5;66;03m# such information and is set up by the scale_* methods. The analogous\u001b[39;00m\n\u001b[32m    632\u001b[39m \u001b[38;5;66;03m# information for numeric axes would be information about log scales.\u001b[39;00m\n\u001b[32m    633\u001b[39m \u001b[38;5;28mself\u001b[39m._var_ordered = {\u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}  \u001b[38;5;66;03m# alt., used DefaultDict\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[38;5;66;03m# TODO Lots of tests assume that these are called to initialize the\u001b[39;00m\n\u001b[32m    637\u001b[39m \u001b[38;5;66;03m# mappings to default values on class initialization. I'd prefer to\u001b[39;00m\n\u001b[32m    638\u001b[39m \u001b[38;5;66;03m# move away from that and only have a mapping when explicitly called.\u001b[39;00m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mhue\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstyle\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\localuser\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\seaborn\\_base.py:679\u001b[39m, in \u001b[36mVectorPlotter.assign_variables\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    675\u001b[39m     \u001b[38;5;66;03m# When dealing with long-form input, use the newer PlotData\u001b[39;00m\n\u001b[32m    676\u001b[39m     \u001b[38;5;66;03m# object (internal but introduced for the objects interface)\u001b[39;00m\n\u001b[32m    677\u001b[39m     \u001b[38;5;66;03m# to centralize / standardize data consumption logic.\u001b[39;00m\n\u001b[32m    678\u001b[39m     \u001b[38;5;28mself\u001b[39m.input_format = \u001b[33m\"\u001b[39m\u001b[33mlong\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m679\u001b[39m     plot_data = \u001b[43mPlotData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    680\u001b[39m     frame = plot_data.frame\n\u001b[32m    681\u001b[39m     names = plot_data.names\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\localuser\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\seaborn\\_core\\data.py:58\u001b[39m, in \u001b[36mPlotData.__init__\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     52\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     53\u001b[39m     data: DataSource,\n\u001b[32m     54\u001b[39m     variables: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, VariableSpec],\n\u001b[32m     55\u001b[39m ):\n\u001b[32m     57\u001b[39m     data = handle_data_source(data)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     frame, names, ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_assign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.frame = frame\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.names = names\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\localuser\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\seaborn\\_core\\data.py:232\u001b[39m, in \u001b[36mPlotData._assign_variables\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m    230\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    231\u001b[39m         err += \u001b[33m\"\u001b[39m\u001b[33mAn entry with this name does not appear in `data`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    235\u001b[39m \n\u001b[32m    236\u001b[39m     \u001b[38;5;66;03m# Otherwise, assume the value somehow represents data\u001b[39;00m\n\u001b[32m    237\u001b[39m \n\u001b[32m    238\u001b[39m     \u001b[38;5;66;03m# Ignore empty data structures\u001b[39;00m\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(val) == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mValueError\u001b[39m: Could not interpret value `UPOS` for `y`. An entry with this name does not appear in `data`."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fr_data_m = fr_data.melt(\n",
    "    id_vars=['target_ud'],\n",
    "    value_vars=['in_domain', 'best_out_domain', 'best_transfer_lang'],\n",
    "    var_name='score_type',\n",
    "    value_name='UPOs'\n",
    ")\n",
    "\n",
    "pyplot.figure(figsize=(10,6))\n",
    "sns.violinplot(x='score_type', y='UPOS', data=fr_data_m, inner='quartile', palette='Set2')\n",
    "pyplot.ylabel('UPOS score')\n",
    "pyplot.xlabel('Evaluation Type')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bb95e6",
   "metadata": {},
   "source": [
    "16. For each language and each test corpus, determine which training language yields the best cross-lingual transfer score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db21974f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5240acc0",
   "metadata": {},
   "source": [
    "17. For a given language, plot the distribution of the number of distinct training languages that achieve the best transfer score. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e667f0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbca6f78",
   "metadata": {},
   "source": [
    "IMPACT OF LINGUISTIC TYPOLOGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a8c8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  7952  100  7952    0     0   7900      0  0:00:01  0:00:01 --:--:--  7952\n",
      "100  7952  100  7952    0     0   7895      0  0:00:01  0:00:01 --:--:--  7952\n"
     ]
    }
   ],
   "source": [
    "# Downloading linguistic data.\n",
    "!curl -O https://pages.llf-paris.fr/~gwisniewski/assets/2025/language_family.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "719caa0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abkhaz</td>\n",
       "      <td>Abkhaz-Adyge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abaza</td>\n",
       "      <td>Abkhaz-Adyge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>Indo-European</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assyrian</td>\n",
       "      <td>Afro-Asiatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Levantine Arabic</td>\n",
       "      <td>Afro-Asiatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Umbrian</td>\n",
       "      <td>Indo-European</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Yoruba</td>\n",
       "      <td>Atlantic-Congo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Nheengatu</td>\n",
       "      <td>Tupian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Cantonese</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   language          family\n",
       "0                    Abkhaz    Abkhaz-Adyge\n",
       "1                     Abaza    Abkhaz-Adyge\n",
       "2                 Afrikaans   Indo-European\n",
       "3                  Assyrian    Afro-Asiatic\n",
       "4    South Levantine Arabic    Afro-Asiatic\n",
       "..                      ...             ...\n",
       "163                 Umbrian   Indo-European\n",
       "164                  Yoruba  Atlantic-Congo\n",
       "165               Nheengatu          Tupian\n",
       "166               Cantonese    Sino-Tibetan\n",
       "167                 Chinese    Sino-Tibetan\n",
       "\n",
       "[168 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"language_family.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    langs = json.load(f) # Here we open thee .json file; it is a list of dictionaries.  \n",
    "lang_data = pd.DataFrame(langs) # We turn it into a DataFrame like this.\n",
    "lang_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2e9568",
   "metadata": {},
   "source": [
    " 18. Why is it natural that transfer performance varies with the source language?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4189707f",
   "metadata": {},
   "source": [
    "==> As already stated in question 13, it is quite natural that a model performs best on languages related to the one the model was trained on. To elaborate, languages from the same group or family tend to have the same UPoS classes and those classes tend to have the same properties. For example, Russian tends to mark gender on adjectives according to the gender of the noun they are dependent on, while English does not - since Ukrainian adjectives work the same way as Russian ones do, it would be easier for a model trained on Ukrainian to predict UPoS tags on Russian rather than English. Information about word classes is important for UPoS since it pays attention to the context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f126107",
   "metadata": {},
   "source": [
    "19. Why is it useful to predict which source language will yield the best performance for a given target?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb572a6",
   "metadata": {},
   "source": [
    "==> One useful application I can think of is low-resourced languages. There are some morphological parsers that can do UPoS labeling automatically for some languages: English, German, Russian, Japanese etc. Those languages are usually ones with efficient data. However, what should you do if you want to get UPoS labels for a language that does not have a morphological parser yet? Looking at the current results, it seems logical to use a model trained on a related language with more data available since it might be successful at labeling data on another language. The information on the best performing language might also be useful for the exact opposite reason - proving that languages are related if they perform well at labeling each other's words with UPoS classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b52210d",
   "metadata": {},
   "source": [
    " 20. Define the notion diachronic and synchronic similarities used in typological linguistics. Which one should you use to predict which source language will yield the best performance for a given target? Is the typological information available on Glottolog useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69234cb",
   "metadata": {},
   "source": [
    " 21. How many language families are represented in language_family.json? Which family is most represented? What is the distribution of languages per family?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e8c945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_data[\"family\"].nunique() # 32 unique language families in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23af7f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Indo-European'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_data[\"family\"].value_counts().idxmax() # The most languages are found in the most famous Indo-European family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db8af62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "family\n",
       "Indo-European              76\n",
       "Afro-Asiatic               13\n",
       "Tupian                     11\n",
       "Uralic                     11\n",
       "Turkic                      9\n",
       "['None']                    7\n",
       "Austronesian                4\n",
       "Atlantic-Congo              4\n",
       "Sino-Tibetan                3\n",
       "Dravidian                   3\n",
       "Abkhaz-Adyge                2\n",
       "Sign Language               2\n",
       "Arawan                      2\n",
       "Uto-Aztecan                 2\n",
       "Mande                       1\n",
       "Arawakan                    1\n",
       "Athabaskan-Eyak-Tlingit     1\n",
       "Eskimo-Aleut                1\n",
       "Mongolic-Khitan             1\n",
       "Chukotko-Kamchatkan         1\n",
       "Bororoan                    1\n",
       "Kartvelian                  1\n",
       "Koreanic                    1\n",
       "Japonic                     1\n",
       "Bookkeeping                 1\n",
       "Chibchan                    1\n",
       "Mayan                       1\n",
       "Tungusic                    1\n",
       "Tai-Kadai                   1\n",
       "Austroasiatic               1\n",
       "Pama-Nyungan                1\n",
       "Nuclear-Macro-Je            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_data[\"family\"].value_counts() # As can be seen, the majority of families contain just 1 language in the dataset (18 out of 32).\n",
    "# There are also some NaNs and the margin between the most represented and second most represented is extremely large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b517b45",
   "metadata": {},
   "source": [
    "For the next questions we will merge the UD data and lingustic data into one new data_full DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "836158af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_lang</th>\n",
       "      <th>model_lang</th>\n",
       "      <th>target_ud</th>\n",
       "      <th>model_ud</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Words</th>\n",
       "      <th>UPOS</th>\n",
       "      <th>XPOS</th>\n",
       "      <th>UFeats</th>\n",
       "      <th>...</th>\n",
       "      <th>Lemmas</th>\n",
       "      <th>UAS</th>\n",
       "      <th>LAS</th>\n",
       "      <th>CLAS</th>\n",
       "      <th>MLAS</th>\n",
       "      <th>BLEX</th>\n",
       "      <th>target_iso3</th>\n",
       "      <th>model_iso3</th>\n",
       "      <th>source_family</th>\n",
       "      <th>target_family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abkhaz</td>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>ab_abnc</td>\n",
       "      <td>af_afribooms</td>\n",
       "      <td>99.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.95</td>\n",
       "      <td>28.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.12</td>\n",
       "      <td>...</td>\n",
       "      <td>32.32</td>\n",
       "      <td>9.21</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>abk</td>\n",
       "      <td>afr</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Abkhaz-Adyge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abkhaz</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>ab_abnc</td>\n",
       "      <td>ar_padt</td>\n",
       "      <td>98.69</td>\n",
       "      <td>6.38</td>\n",
       "      <td>98.69</td>\n",
       "      <td>27.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.87</td>\n",
       "      <td>...</td>\n",
       "      <td>31.32</td>\n",
       "      <td>9.68</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abk</td>\n",
       "      <td>arb</td>\n",
       "      <td>Afro-Asiatic</td>\n",
       "      <td>Abkhaz-Adyge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abkhaz</td>\n",
       "      <td>Belarusian</td>\n",
       "      <td>ab_abnc</td>\n",
       "      <td>be_hse</td>\n",
       "      <td>99.51</td>\n",
       "      <td>78.49</td>\n",
       "      <td>99.51</td>\n",
       "      <td>43.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.47</td>\n",
       "      <td>...</td>\n",
       "      <td>32.10</td>\n",
       "      <td>20.10</td>\n",
       "      <td>10.62</td>\n",
       "      <td>4.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>abk</td>\n",
       "      <td>bel</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Abkhaz-Adyge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abkhaz</td>\n",
       "      <td>Bulgarian</td>\n",
       "      <td>ab_abnc</td>\n",
       "      <td>bg_btb</td>\n",
       "      <td>99.95</td>\n",
       "      <td>31.17</td>\n",
       "      <td>99.95</td>\n",
       "      <td>36.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.60</td>\n",
       "      <td>...</td>\n",
       "      <td>31.21</td>\n",
       "      <td>18.90</td>\n",
       "      <td>6.99</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abk</td>\n",
       "      <td>bul</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Abkhaz-Adyge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abkhaz</td>\n",
       "      <td>Catalan</td>\n",
       "      <td>ab_abnc</td>\n",
       "      <td>ca_ancora</td>\n",
       "      <td>99.88</td>\n",
       "      <td>50.22</td>\n",
       "      <td>99.88</td>\n",
       "      <td>33.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.30</td>\n",
       "      <td>...</td>\n",
       "      <td>31.59</td>\n",
       "      <td>8.89</td>\n",
       "      <td>4.63</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abk</td>\n",
       "      <td>cat</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Abkhaz-Adyge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43338</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>zh_pud</td>\n",
       "      <td>vi_vtb</td>\n",
       "      <td>21.49</td>\n",
       "      <td>96.20</td>\n",
       "      <td>21.49</td>\n",
       "      <td>19.60</td>\n",
       "      <td>16.77</td>\n",
       "      <td>21.19</td>\n",
       "      <td>...</td>\n",
       "      <td>21.20</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.23</td>\n",
       "      <td>cmn</td>\n",
       "      <td>vie</td>\n",
       "      <td>Austroasiatic</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43339</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Wolof</td>\n",
       "      <td>zh_pud</td>\n",
       "      <td>wo_wtb</td>\n",
       "      <td>12.02</td>\n",
       "      <td>98.80</td>\n",
       "      <td>12.02</td>\n",
       "      <td>10.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.56</td>\n",
       "      <td>...</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>cmn</td>\n",
       "      <td>wol</td>\n",
       "      <td>Atlantic-Congo</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43340</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Classical Armenian</td>\n",
       "      <td>zh_pud</td>\n",
       "      <td>xcl_caval</td>\n",
       "      <td>15.61</td>\n",
       "      <td>96.88</td>\n",
       "      <td>15.61</td>\n",
       "      <td>14.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.83</td>\n",
       "      <td>...</td>\n",
       "      <td>15.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>cmn</td>\n",
       "      <td>xcl</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43341</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>zh_pud</td>\n",
       "      <td>zh_gsd</td>\n",
       "      <td>88.01</td>\n",
       "      <td>97.47</td>\n",
       "      <td>88.01</td>\n",
       "      <td>78.89</td>\n",
       "      <td>84.61</td>\n",
       "      <td>86.67</td>\n",
       "      <td>...</td>\n",
       "      <td>87.95</td>\n",
       "      <td>60.73</td>\n",
       "      <td>49.41</td>\n",
       "      <td>43.02</td>\n",
       "      <td>34.71</td>\n",
       "      <td>42.99</td>\n",
       "      <td>cmn</td>\n",
       "      <td>cmn</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43342</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>zh_pud</td>\n",
       "      <td>zh_gsdsimp</td>\n",
       "      <td>57.82</td>\n",
       "      <td>99.55</td>\n",
       "      <td>57.82</td>\n",
       "      <td>50.53</td>\n",
       "      <td>55.38</td>\n",
       "      <td>56.41</td>\n",
       "      <td>...</td>\n",
       "      <td>57.74</td>\n",
       "      <td>23.72</td>\n",
       "      <td>20.50</td>\n",
       "      <td>14.33</td>\n",
       "      <td>11.50</td>\n",
       "      <td>14.31</td>\n",
       "      <td>cmn</td>\n",
       "      <td>cmn</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43343 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target_lang          model_lang target_ud      model_ud  Tokens  \\\n",
       "0          Abkhaz           Afrikaans   ab_abnc  af_afribooms   99.95   \n",
       "1          Abkhaz              Arabic   ab_abnc       ar_padt   98.69   \n",
       "2          Abkhaz          Belarusian   ab_abnc        be_hse   99.51   \n",
       "3          Abkhaz           Bulgarian   ab_abnc        bg_btb   99.95   \n",
       "4          Abkhaz             Catalan   ab_abnc     ca_ancora   99.88   \n",
       "...           ...                 ...       ...           ...     ...   \n",
       "43338     Chinese          Vietnamese    zh_pud        vi_vtb   21.49   \n",
       "43339     Chinese               Wolof    zh_pud        wo_wtb   12.02   \n",
       "43340     Chinese  Classical Armenian    zh_pud     xcl_caval   15.61   \n",
       "43341     Chinese             Chinese    zh_pud        zh_gsd   88.01   \n",
       "43342     Chinese             Chinese    zh_pud    zh_gsdsimp   57.82   \n",
       "\n",
       "       Sentences  Words   UPOS   XPOS  UFeats  ...  Lemmas    UAS    LAS  \\\n",
       "0           0.00  99.95  28.32   0.00   37.12  ...   32.32   9.21   3.94   \n",
       "1           6.38  98.69  27.87   0.00   41.87  ...   31.32   9.68   3.01   \n",
       "2          78.49  99.51  43.37   0.00   35.47  ...   32.10  20.10  10.62   \n",
       "3          31.17  99.95  36.96   0.00   33.60  ...   31.21  18.90   6.99   \n",
       "4          50.22  99.88  33.26   0.00   44.30  ...   31.59   8.89   4.63   \n",
       "...          ...    ...    ...    ...     ...  ...     ...    ...    ...   \n",
       "43338      96.20  21.49  19.60  16.77   21.19  ...   21.20   1.39   1.28   \n",
       "43339      98.80  12.02  10.54   0.00   11.56  ...   11.93   0.53   0.52   \n",
       "43340      96.88  15.61  14.16   0.00   14.83  ...   15.14   0.19   0.15   \n",
       "43341      97.47  88.01  78.89  84.61   86.67  ...   87.95  60.73  49.41   \n",
       "43342      99.55  57.82  50.53  55.38   56.41  ...   57.74  23.72  20.50   \n",
       "\n",
       "        CLAS   MLAS   BLEX  target_iso3 model_iso3   source_family  \\\n",
       "0       0.49   0.02   0.07          abk        afr   Indo-European   \n",
       "1       1.06   0.00   0.00          abk        arb    Afro-Asiatic   \n",
       "2       4.24   0.00   0.24          abk        bel   Indo-European   \n",
       "3       4.25   0.00   0.00          abk        bul   Indo-European   \n",
       "4       1.50   0.14   0.00          abk        cat   Indo-European   \n",
       "...      ...    ...    ...          ...        ...             ...   \n",
       "43338   0.24   0.16   0.23          cmn        vie   Austroasiatic   \n",
       "43339   0.26   0.00   0.26          cmn        wol  Atlantic-Congo   \n",
       "43340   0.00   0.00   0.00          cmn        xcl   Indo-European   \n",
       "43341  43.02  34.71  42.99          cmn        cmn    Sino-Tibetan   \n",
       "43342  14.33  11.50  14.31          cmn        cmn    Sino-Tibetan   \n",
       "\n",
       "      target_family  \n",
       "0      Abkhaz-Adyge  \n",
       "1      Abkhaz-Adyge  \n",
       "2      Abkhaz-Adyge  \n",
       "3      Abkhaz-Adyge  \n",
       "4      Abkhaz-Adyge  \n",
       "...             ...  \n",
       "43338  Sino-Tibetan  \n",
       "43339  Sino-Tibetan  \n",
       "43340  Sino-Tibetan  \n",
       "43341  Sino-Tibetan  \n",
       "43342  Sino-Tibetan  \n",
       "\n",
       "[43343 rows x 21 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full = data.merge(lang_data.rename(columns={\"language\": \"model_lang\", \"family\": \"source_family\"}),\n",
    "                       on=\"model_lang\") \\\n",
    "                        .merge(lang_data.rename(columns={\"language\": \"target_lang\", \"family\": \"target_family\"}),\n",
    "                            on=\"target_lang\")\n",
    "data_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62045135",
   "metadata": {},
   "source": [
    "22. Compute, for every test corpus, the family of the best-performing source language. Report the proportion of corpora whose best source comes from the same family as the target language. Interpret the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ed1b6820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7762711864406779)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_full.loc[data_full.groupby(\"target_ud\").UPOS.idxmax()].eval(\"source_family == target_family\")).mean() \n",
    "# Let us first prepare a merged dataset taking the source and target family columns from linguistics data and renaming them.\n",
    "# Then select the best performing source language for every test corpus and check whether its family matches the target family.\n",
    "# If yes, print the average score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc98d42",
   "metadata": {},
   "source": [
    "==> This result proves that models trained on related languages outperform non-related languages in UPoS labeling task. 77.63% of the best performing languages come from the same family as the test language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a21e302",
   "metadata": {},
   "source": [
    "23. Plot the distributions of transfer scores by grouping pairs into (i) same-family and (ii) different-family. Comment on central tendency and dispersion, and whether within-family transfer confers a systematic advantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b45fbd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "families = [data_full.loc[data_full.source_family == data_full.target_family, \"UPOS\"],\n",
    "            data_full.loc[data_full.source_family != data_full.target_family, \"UPOS\"]]\n",
    "pyplot.violinplot(families, showmeans=True)\n",
    "pyplot.xticks([1,2],[\"Same family\", \"Different family\"])\n",
    "pyplot.ylabel(\"UPOS\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96039b11",
   "metadata": {},
   "source": [
    "Yes, within-family transfer have a systematic advantage. Same family plot shows higher mean (horizontal line) UPoS scores; the figure for same family is tighter and more narrow (dispersion), showing it is more stable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c0c7a5",
   "metadata": {},
   "source": [
    "24. For each corpus where both are available, compute the difference between the in-domain score and the best transfer score obtained from each language family. Analyse the distribution of these deltas (e.g., median, IQR, tails) and discuss which families tend to close the in-domain gap, and in which conditions they fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e96299ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>source_family</th>\n",
       "      <th>Afro-Asiatic</th>\n",
       "      <th>Atlantic-Congo</th>\n",
       "      <th>Austroasiatic</th>\n",
       "      <th>Austronesian</th>\n",
       "      <th>Dravidian</th>\n",
       "      <th>Indo-European</th>\n",
       "      <th>Japonic</th>\n",
       "      <th>Kartvelian</th>\n",
       "      <th>Koreanic</th>\n",
       "      <th>Sino-Tibetan</th>\n",
       "      <th>Turkic</th>\n",
       "      <th>Uralic</th>\n",
       "      <th>['None']</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_ud</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ab_abnc</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abq_atb</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>af_afribooms</th>\n",
       "      <td>40.03</td>\n",
       "      <td>69.13</td>\n",
       "      <td>67.32</td>\n",
       "      <td>43.69</td>\n",
       "      <td>44.83</td>\n",
       "      <td>11.73</td>\n",
       "      <td>71.51</td>\n",
       "      <td>87.90</td>\n",
       "      <td>69.03</td>\n",
       "      <td>97.78</td>\n",
       "      <td>49.19</td>\n",
       "      <td>45.26</td>\n",
       "      <td>25.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aii_as</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ajp_madar</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zh_gsd</th>\n",
       "      <td>66.53</td>\n",
       "      <td>84.31</td>\n",
       "      <td>68.04</td>\n",
       "      <td>82.94</td>\n",
       "      <td>72.59</td>\n",
       "      <td>63.92</td>\n",
       "      <td>52.12</td>\n",
       "      <td>64.39</td>\n",
       "      <td>72.27</td>\n",
       "      <td>75.67</td>\n",
       "      <td>63.78</td>\n",
       "      <td>68.08</td>\n",
       "      <td>65.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zh_gsdsimp</th>\n",
       "      <td>67.64</td>\n",
       "      <td>84.29</td>\n",
       "      <td>68.90</td>\n",
       "      <td>84.12</td>\n",
       "      <td>72.99</td>\n",
       "      <td>64.18</td>\n",
       "      <td>57.16</td>\n",
       "      <td>64.57</td>\n",
       "      <td>73.89</td>\n",
       "      <td>76.62</td>\n",
       "      <td>65.17</td>\n",
       "      <td>69.19</td>\n",
       "      <td>66.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zh_hk</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zh_patentchar</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zh_pud</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "source_family  Afro-Asiatic  Atlantic-Congo  Austroasiatic  Austronesian  \\\n",
       "target_ud                                                                  \n",
       "ab_abnc                 NaN             NaN            NaN           NaN   \n",
       "abq_atb                 NaN             NaN            NaN           NaN   \n",
       "af_afribooms          40.03           69.13          67.32         43.69   \n",
       "aii_as                  NaN             NaN            NaN           NaN   \n",
       "ajp_madar               NaN             NaN            NaN           NaN   \n",
       "...                     ...             ...            ...           ...   \n",
       "zh_gsd                66.53           84.31          68.04         82.94   \n",
       "zh_gsdsimp            67.64           84.29          68.90         84.12   \n",
       "zh_hk                   NaN             NaN            NaN           NaN   \n",
       "zh_patentchar           NaN             NaN            NaN           NaN   \n",
       "zh_pud                  NaN             NaN            NaN           NaN   \n",
       "\n",
       "source_family  Dravidian  Indo-European  Japonic  Kartvelian  Koreanic  \\\n",
       "target_ud                                                                \n",
       "ab_abnc              NaN            NaN      NaN         NaN       NaN   \n",
       "abq_atb              NaN            NaN      NaN         NaN       NaN   \n",
       "af_afribooms       44.83          11.73    71.51       87.90     69.03   \n",
       "aii_as               NaN            NaN      NaN         NaN       NaN   \n",
       "ajp_madar            NaN            NaN      NaN         NaN       NaN   \n",
       "...                  ...            ...      ...         ...       ...   \n",
       "zh_gsd             72.59          63.92    52.12       64.39     72.27   \n",
       "zh_gsdsimp         72.99          64.18    57.16       64.57     73.89   \n",
       "zh_hk                NaN            NaN      NaN         NaN       NaN   \n",
       "zh_patentchar        NaN            NaN      NaN         NaN       NaN   \n",
       "zh_pud               NaN            NaN      NaN         NaN       NaN   \n",
       "\n",
       "source_family  Sino-Tibetan  Turkic  Uralic  ['None']  \n",
       "target_ud                                              \n",
       "ab_abnc                 NaN     NaN     NaN       NaN  \n",
       "abq_atb                 NaN     NaN     NaN       NaN  \n",
       "af_afribooms          97.78   49.19   45.26     25.40  \n",
       "aii_as                  NaN     NaN     NaN       NaN  \n",
       "ajp_madar               NaN     NaN     NaN       NaN  \n",
       "...                     ...     ...     ...       ...  \n",
       "zh_gsd                75.67   63.78   68.08     65.41  \n",
       "zh_gsdsimp            76.62   65.17   69.19     66.61  \n",
       "zh_hk                   NaN     NaN     NaN       NaN  \n",
       "zh_patentchar           NaN     NaN     NaN       NaN  \n",
       "zh_pud                  NaN     NaN     NaN       NaN  \n",
       "\n",
       "[295 rows x 13 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_dom_score = data_full.query(\"model_lang == target_lang and model_ud == target_ud\").groupby(\"target_ud\")[\"UPOS\"].max()\n",
    "(data_full.query(\"model_lang != target_lang\").groupby([\"target_ud\", \"source_family\"])[\"UPOS\"].max()).unstack().rsub(in_dom_score, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dadf272a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_ud  source_family \n",
       "ab_abnc    Afro-Asiatic      56.06\n",
       "           Atlantic-Congo    33.14\n",
       "           Austroasiatic     29.59\n",
       "           Austronesian      35.03\n",
       "           Dravidian         35.68\n",
       "                             ...  \n",
       "zh_pud     Koreanic          16.17\n",
       "           Sino-Tibetan      11.14\n",
       "           Turkic            20.83\n",
       "           Uralic            18.61\n",
       "           ['None']          20.13\n",
       "Name: UPOS, Length: 3818, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_dom = data_full.query(\"model_lang == target_lang and model_ud == target_ud\").groupby(\"target_ud\")[\"UPOS\"].max()\n",
    "data_full.query(\"model_lang != target_lang\").groupby([\"target_ud\", \"source_family\"])[\"UPOS\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0a99dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
